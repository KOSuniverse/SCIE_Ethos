# Jarvis Knowledge Base Assistant

A modular, AI-powered knowledge base assistant that integrates with Google Drive to provide intelligent document analysis, Q&A capabilities, and predictive modeling.

## Project Structure

```
â”œâ”€â”€ main.py                     # Main Streamlit application
â”œâ”€â”€ llm_client.py              # OpenAI integration and LLM operations
â”œâ”€â”€ modeling.py                # Predictive modeling functionality
â”œâ”€â”€ gdrive_utils.py            # Google Drive service account integration
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py           # Package initialization
â”‚   â”œâ”€â”€ retry.py              # OpenAI retry logic
â”‚   â”œâ”€â”€ gdrive.py             # Google Drive helper functions
â”‚   â”œâ”€â”€ metadata.py           # Metadata operations
â”‚   â”œâ”€â”€ text_utils.py         # Text processing and chunking
â”‚   â”œâ”€â”€ excel_qa.py           # Excel analysis with charts
â”‚   â””â”€â”€ column_mapping.py     # Column mapping and aliases
â””â”€â”€ README.md                 # This file
```

## Features

- ğŸ” **Intelligent Document Search** - Hybrid keyword + semantic search
- ğŸ“Š **Excel Q&A with Charts** - Automated data analysis and visualization
- ğŸ¤– **AI-Powered Insights** - Root cause analysis and business insights
- ğŸ“ˆ **Predictive Modeling** - Build, train, and deploy ML models
- ğŸ’¾ **Answer Caching** - Learn from previous queries
- ğŸ”§ **Column Mapping** - Standardize Excel column names
- ğŸ“ **Google Drive Integration** - Seamless file access and storage

## Setup

### ğŸŒ **Cloud-Native Deployment (Recommended):**

**No local installation needed!** This runs entirely in the cloud:

1. **Upload Code to GitHub** (through GitHub web interface or GitHub Desktop):
   - Create a new repository on GitHub.com
   - Upload all your `.py` files, `requirements.txt`, and `README.md`
   - **Your documents stay in Google Drive - don't upload them to GitHub!**

2. **Deploy to Streamlit Cloud:**
   - Go to [share.streamlit.io](https://share.streamlit.io)
   - Connect your GitHub repository
   - Set main file path: `main.py`
   - Streamlit Cloud automatically installs all dependencies from `requirements.txt`

3. **Configure Secrets** in Streamlit Cloud dashboard:
   - Add your `OPENAI_API_KEY`
   - Add your `[gdrive_service_account]` credentials (you already have these)

**That's it! Everything runs in the cloud.** â˜ï¸

### ğŸ“ **What Goes Where:**

**GitHub (Code Only):**
- âœ… `main.py`, `llm_client.py`, `modeling.py`, etc.
- âœ… `utils/` folder with all `.py` files
- âœ… `requirements.txt`, `README.md`, `.gitignore`
- âŒ **NO documents** (Excel, Word, PDF files)
- âŒ **NO secrets** (handled in Streamlit Cloud)

**Google Drive (Documents Only):**
- âœ… Your Excel files, Word docs, PDFs
- âœ… Metadata files (auto-generated)
- âœ… ML models (auto-saved)
- âŒ **NO code files**

### ğŸ’» **No Command Line Needed:**

You can do everything through web interfaces:
- **GitHub.com** - Upload your code files using drag & drop
- **share.streamlit.io** - Deploy with a few clicks
- **Google Drive** - Your documents are already there!

*The git commands in the previous section are only if you prefer command line, but you can use GitHub's web interface instead.*

## Google Drive Structure Expected

```
Project_Root/
â”œâ”€â”€ 01_Project_Plan/
â”‚   â””â”€â”€ _metadata/           # Metadata storage
â”œâ”€â”€ 04_Data/
â”‚   â””â”€â”€ Models/             # ML model storage
â””â”€â”€ [Other folders with documents]
```

## Usage

1. **Ask Questions** - Type natural language questions about your documents
2. **Edit Aliases** - Use the checkbox to standardize column names
3. **Generate Charts** - Excel files automatically offer chart generation
4. **Build Models** - Use AI to create predictive models from your data
5. **View History** - Check previous queries and results

## Dependencies

- **Streamlit** - Web interface and cloud deployment
- **OpenAI** - LLM capabilities and embeddings
- **Google Drive API** - File access using service account
- **Data Science Stack** - pandas, matplotlib, seaborn, scikit-learn
- **Document Processing** - openpyxl, python-docx, pdfplumber
- **ML Libraries** - scikit-learn, xgboost for predictive modeling

## Streamlit Cloud Deployment

This project is **100% cloud-native** and requires:

**âœ… What You Need:**
- GitHub repository (free)
- Streamlit Cloud account (free) 
- Google Drive with your documents
- OpenAI API key
- Google service account (you have this)

**âŒ What You DON'T Need:**
- Local Python installation
- Local file storage
- Local authentication files
- Local servers or databases

**ğŸš€ Deployment Process:**
1. Push code to GitHub â†’ 2. Connect to Streamlit Cloud â†’ 3. Add secrets â†’ 4. LIVE!

All processing happens in Streamlit's cloud infrastructure, accessing your Google Drive files through the service account.

## Note

The application uses service account credentials stored in Streamlit secrets for secure Google Drive access. No local authentication files needed.
